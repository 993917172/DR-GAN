{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiple_DR_GAN\n",
    "\n",
    "ジュネレータに同じ人の複数の画像（異なるポーズ，シーンetc)を入れ，出力されたそれぞれの特徴量を\n",
    "重み付けして足し合わせた特徴量を元に画像を生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator の定義\n",
    "\n",
    "single-image_DR_GAN と同じ\n",
    "> - 論文で用いられている  TensorFlow のConv オプション padding=\"SAME\"と同じ挙動を再現するために padding layer を間に追加\n",
    "- 入力は バッチ数(B)ｘ96x96x3\n",
    "- 個人の識別(Nd+1) と　姿勢の推定(Np)を同時に行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, Nd, Np):\n",
    "        super(Discriminator, self).__init__()\n",
    "        convLayers = [\n",
    "            nn.Conv2d(1, 32, 3, 1, 1, bias=False), # Bx1x96x96 -> Bx32x96x96\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, 3, 1, 1, bias=False), # Bx32x96x96 -> Bx64x96x96\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # Bx64x96x96 -> Bx64x97x97\n",
    "            nn.Conv2d(64, 64, 3, 2, 0, bias=False), # Bx64x97x97 -> Bx64x48x48\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 64, 3, 1, 1, bias=False), # Bx64x48x48 -> Bx64x48x48\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, 3, 1, 1, bias=False), # Bx64x48x48 -> Bx128x48x48\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # Bx128x48x48 -> Bx128x49x49\n",
    "            nn.Conv2d(128, 128, 3, 2, 0, bias=False), #  Bx128x49x49 -> Bx128x24x24\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(128, 96, 3, 1, 1, bias=False), #  Bx128x24x24 -> Bx96x24x24\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(96, 192, 3, 1, 1, bias=False), #  Bx96x24x24 -> Bx192x24x24\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # Bx192x24x24 -> Bx192x25x25\n",
    "            nn.Conv2d(192, 192, 3, 2, 0, bias=False), # Bx192x25x25 -> Bx192x12x12\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(192, 128, 3, 1, 1, bias=False), # Bx192x12x12 -> Bx128x12x12\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(128, 256, 3, 1, 0, bias=False), # Bx128x12x12 -> Bx256x12x12\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # Bx256x12x12 -> Bx256x13x13\n",
    "            nn.Conv2d(256, 256, 3, 2, 0, bias=False),  # Bx256x13x13 -> Bx256x6x6\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 160, 3, 1, 1, bias=False), # Bx256x6x6 -> Bx160x6x6\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(160, 321, 3, 1, 1, bias=False), # Bx160x6x6 -> Bx320x6x6\n",
    "            nn.BatchNorm2d(321),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(6, stride=1), #  Bx320x6x6 -> Bx320x1x1\n",
    "        ]\n",
    "        \n",
    "        self.convLayers = nn.Sequential(*convLayers)\n",
    "        self.fc = nn.Linear(321, Nd+1+Np)\n",
    "        \n",
    "        # 重みは全て N(0, 0.02) で初期化\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0, 0.02)\n",
    "                \n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.02)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # 畳み込み -> 平均プーリングの結果 B x 321 x 1 x 1の出力を得る\n",
    "        x = self.convLayers(input)\n",
    "        \n",
    "        # １次元の次元を削除\n",
    "        x = x.squeeze()\n",
    "        \n",
    "        # 全結合 \n",
    "        x = self.fc(x) # Bx321 -> B x (Nd+1+Np)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator の定義\n",
    "\n",
    "- G_enc は 同一人物に n 枚の画像があるとして nB x 1 x 96 x 96 -> B x n x 321 -> B x 320 と特徴量をencode\n",
    "- G_dec は single-image DR_GANと同じ\n",
    "> single-image の時\n",
    "    - G_enc は Discriminator と最後の全結合層が無い以外同じ構造\n",
    "    - G_dec のアップサンプリング時は，ダウンサンプリング時に Zeropadding を行なったことの逆で，ConvTranspose2d 後に Crop（negative padding?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## nn.Module を継承しても， super でコンストラクタを呼び出さないと メンバ変数 self._modues が\n",
    "## 定義されずに後の重み初期化の際にエラーを出す\n",
    "## sef._modules はモジュールが格納するモジュール名を格納しておくリスト\n",
    "\n",
    "class Crop(nn.Module):\n",
    "    def __init__(self, crop_list):\n",
    "        super().__init__()\n",
    "        \n",
    "        # crop_lsit = [crop_top, crop_bottom, crop_left, crop_right]\n",
    "        self.crop_list = crop_list\n",
    "            \n",
    "    def forward(self, x):\n",
    "        H,W = x.size()\n",
    "        x = x[ crop_list[0] : H - crop_list[1] , crop_list[2] : W - crop_list[3]]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, Np, Nz):\n",
    "        super(Generator, self).__init__()\n",
    "        G_enc_convLayers = [\n",
    "            nn.Conv2d(1, 32, 3, 1, 1, bias=False), # nBx1x96x96 -> nBx32x96x96\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, 3, 1, 1, bias=False), # nBx32x96x96 -> nBx64x96x96\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # nBx64x96x96 -> nBx64x97x97\n",
    "            nn.Conv2d(64, 64, 3, 2, 0, bias=False), # nBx64x97x97 -> nBx64x48x48\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 64, 3, 1, 1, bias=False), # nBx64x48x48 -> nBx64x48x48\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, 3, 1, 1, bias=False), # nBx64x48x48 -> nBx128x48x48\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # nBx128x48x48 -> nBx128x49x49\n",
    "            nn.Conv2d(128, 128, 3, 2, 0, bias=False), #  nBx128x49x49 -> nBx128x24x24\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(128, 96, 3, 1, 1, bias=False), #  nBx128x24x24 -> nBx96x24x24\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(96, 192, 3, 1, 1, bias=False), #  nBx96x24x24 -> nBx192x24x24\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # nBx192x24x24 -> nBx192x25x25\n",
    "            nn.Conv2d(192, 192, 3, 2, 0, bias=False), # nBx192x25x25 -> nBx192x12x12\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(192, 128, 3, 1, 1, bias=False), # nBx192x12x12 -> nBx128x12x12\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(128, 256, 3, 1, 0, bias=False), # nBx128x12x12 -> nBx256x12x12\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),                      # nBx256x12x12 -> nBx256x13x13\n",
    "            nn.Conv2d(256, 256, 3, 2, 0, bias=False),  # nBx256x13x13 -> nBx256x6x6\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 160, 3, 1, 1, bias=False), # nBx256x6x6 -> nBx160x6x6\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            # 同一人物の画像の特徴量を足し合わせる際の重みを示す値 w を１次元分チャネルに追加\n",
    "            nn.Conv2d(160, 321, 3, 1, 1, bias=False), # nBx160x6x6 -> nBx321x6x6\n",
    "            nn.BatchNorm2d(321),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(6, stride=1), #  nBx321x6x6 -> nBx320x1x1\n",
    "            \n",
    "        ]\n",
    "        self.G_enc_convLayers = nn.Sequential(*G_enc_convLayers)\n",
    "        \n",
    "        G_dec_convLayers = [\n",
    "            nn.ConvTranspose2d(320,160, 3,1,1, bias=False), # Bx320x6x6 -> Bx160x6x6\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(160, 256, 3,1,1, bias=False), # Bx160x6x6 -> Bx256x6x6\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(160, 256, 3,2,0, bias=False), # Bx256x6x6 -> Bx256x13x13\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            Crop([0, 1, 0, 1]),\n",
    "            nn.ConvTranspose2d(256, 128, 3,1,1, bias=False), # Bx256x12x12 -> Bx128x12x12  \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(128, 192,  3,1,1, bias=False), # Bx128x12x12 -> Bx192x12x12            \n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(192, 192,  3,2,0, bias=False), # Bx128x12x12 -> Bx192x25x25            \n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ELU(),\n",
    "            Crop([0, 1, 0, 1]),\n",
    "            nn.ConvTranspose2d(192, 96,  3,1,1, bias=False), # Bx192x24x24 -> Bx96x24x24 \n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(96, 128,  3,1,1, bias=False), # Bx96x24x24 -> Bx128x24x24\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(128, 128,  3,2,0, bias=False), # Bx128x24x24 -> Bx128x49x49      \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            Crop([0, 1, 0, 1]),\n",
    "            nn.ConvTranspose2d(128, 64,  3,1,1, bias=False), # Bx128x48x48 -> Bx64x48x48\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(64, 64,  3,1,1, bias=False), # Bx64x48x48 -> Bx64x48x48  \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(64, 64,  3,2,0, bias=False), # Bx64x48x48 -> Bx64x97x97  \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(),\n",
    "            Crop([0, 1, 0, 1]),\n",
    "            nn.ConvTranspose2d(64, 32,  3,1,1, bias=False), # Bx64x96x96 -> Bx32x96x96 \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(32, 1,  3,1,1, bias=False), # Bx32x96x96 -> Bx1x96x96 \n",
    "            nn.ELU(),\n",
    "        ]\n",
    "        \n",
    "        self.G_dec_convLayers = nn.Sequential(*G_dec_convLayers)\n",
    "        \n",
    "        self.G_dec_fc = nn.Linear(320+Np+Nz, 320*6*6)\n",
    "        \n",
    "        # 重みは全て N(0, 0.02) で初期化\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0, 0.02)\n",
    "                \n",
    "            elif isinstance(m, nn.ConvTranspose2d):\n",
    "                m.weight.data.normal_(0, 0.02)\n",
    "                \n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.02)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, input, pose, noise):\n",
    "        \n",
    "        x = self.convLayers(input) # Bx1x96x96 -> Bx320x1x1\n",
    "        \n",
    "        x = x.squeeze()\n",
    "    \n",
    "        x = torch.cat([x, pose, noise], 1)  # Bx320 -> B x (320+Np+Nz)\n",
    "        \n",
    "        x = self.G_dec_fc(x) # B x (320+Np+Nz) -> B x (320x6x6)\n",
    "    \n",
    "        x = x.view(-1, 320, 6, 6) # B x (320x6x6) -> B x 320 x 6 x 6\n",
    "        \n",
    "        x = self.G_dec_convLayers(x) #  B x 320 x 6 x 6 -> Bx1x96x96\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "epoch = 10000\n",
    "# image_size = images.shape[0]\n",
    "# epoch_time = np.ceil(image_size / batch_size)\n",
    "\n",
    "Nd = 200 # number of ID (person)\n",
    "Np = 9 # number of discrite poses\n",
    "Nz = 50 # number of noise dimension\n",
    "\n",
    "lr_Adam = 0.0002\n",
    "m_Adam = 0.5\n",
    "\n",
    "D = Discriminator(Nd, Np)\n",
    "G = Generator(Np, Nz)\n",
    "optimizer_D = optim.Adam(D.parameters())\n",
    "optimizer_G = optim.Adam(G.parameters())\n",
    "loss_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    for i in range(epoch_time):\n",
    "        D.zero_grad()\n",
    "        G.zero_grad()\n",
    "        start = i*batch_size\n",
    "        end = start + batch+size\n",
    "        batch_image = images[start:end]\n",
    "        batch_id_label = id_labels[start:end]\n",
    "        batch_pose_label = pose_labels[start:end]\n",
    "        minibatch_size = len(batch_image)\n",
    "        \n",
    "        # 学習の中で使われるVariable変数の定義\n",
    "        # ラベルの定義\n",
    "        img_tensor = Variable(torch.FloatTensor(batch_image))\n",
    "        id_label_tensor = Variable(torch.FloatTensor(batch_id_label))\n",
    "        pose_label_tensor = Variable(torch.FloatTensor(batch_pose_label))\n",
    "        syn_id_label = np.zeros((batch_size, Nd+1))\n",
    "        syn_id_label[:,-1] = 1\n",
    "        syn_id_label_tensor = Variable(torch.FloatTensor(syn_id_label))\n",
    "        \n",
    "        # ノイズと姿勢コードを生成\n",
    "        fixed_noise_tensor = Variable(torch.FloatTensor(np.random.uniform(-1,1, (batch_size, Nz))))\n",
    "        pose_code = np.zeros((batch_size, Np))\n",
    "        pose_code[:, np.random.randint(Np)] = 1\n",
    "        pose_code_tensor = Variable(torch.FloatTensor(pose_code))\n",
    "        \n",
    "        # Generatorでイメージ生成\n",
    "        generated = G(img_tensor, pose_code_tensor, fixed_noise_tensor)\n",
    "        \n",
    "        # イテレーション毎に交互に D と G の学習，　90%以上の精度の場合は 1:4の比率で学習\n",
    "        if i%2==0:\n",
    "            # Discriminator の学習\n",
    "            real_ouput = D(img_tensor)\n",
    "            syn_ouput = D(generated.detach()) # .detach() をすることでGeneratorのパラメータを更新しない\n",
    "            \n",
    "            # id についての出力とラベル, pose についての出力とラベル それぞれの交差エントロピー誤差を計算\n",
    "            d_loss = loss_criterion(real_ouput[:Nd+1], id_label_tensor) +\\\n",
    "                                    loss_criterion(real_ouput[Nd+1:], pose_label_tensor) +\\\n",
    "                                    loss_criterion(syn_ouput[Nd+1:], syn_id_label_tensor)\n",
    "                    \n",
    "            if d_loss.data[0] > 0.1:\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "                print(\"EPOCH : {0}, D : {1}\".format(e, d_loss.data[0]))\n",
    "        else:\n",
    "            # Generatorの学習\n",
    "            syn_ouput=D(generated)\n",
    "            \n",
    "            # id についての出力と元画像のラベル, poseについての出力と生成時に与えたposeコード それぞれの交差エントロピー誤差を計算\n",
    "            g_loss = loss_criterion(syn_ouput[:Nd+1], id_label_tensor) +\\\n",
    "                                loss_criterion(syn_ouput[Nd+1:], pose_code_tensor) +\\\n",
    "            \n",
    "            optimizer_G.step()\n",
    "            print(\"EPOCH : {0}, D : {1}\".format(e, g_loss.data[0]))\n",
    "    \n",
    "    # 各エポックで学習したモデルを保存， 学習した生成器から画像を生成して保存\n",
    "    torch.save(D, \"D.model\")\n",
    "    torch.save(G, \"G.model\")\n",
    "    fixed_noise_tensor = Variable(torch.FloatTensor(np.random.uniform(-1,1, (batch_size, Nz))))\n",
    "    pose_code = np.zeros((batch_size, Np))\n",
    "    pose_code[:, np.random.randint(Np)] = 1\n",
    "    pose_code_tensor = Variable(torch.FloatTensor(pose_code))\n",
    "    #generated = G()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syn_id_label = np.zeros((batch_size, Nd+1))\n",
    "syn_id_label[:,-1] = 1\n",
    "syn_id_label_tensor = Variable(torch.FloatTensor(syn_id_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(Np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
